"""
Post-Audit Protocol - Automated Execution
Runs after each audit: monitor conversions/AB, scale infra, clean fake data,
prioritize bugfix feedback, show live FOMO, migrate pending enhancements
"""
import os
import time
import logging
from datetime import datetime
from typing import Dict, List

from app.ab_test.engine import ABTestEngine
from app.infrastructure.scaling import InfrastructureScaler
from app.bug_tracking.prioritizer import BugPrioritizer
from app.tasks.enhancement_queue import EnhancementQueue
from scripts.clean_fake_data import main as clean_fake_data

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PostAuditProtocol:
    """Post-Audit Protocol Execution"""
    
    def __init__(self):
        self.ab_engine = ABTestEngine()
        self.scaler = InfrastructureScaler()
        self.bug_prioritizer = BugPrioritizer()
        self.enhancement_queue = EnhancementQueue()
    
    def monitor_conversions_ab(self):
        """Monitor A/B test conversions and auto-switch to winner"""
        logger.info("üìä Step 1: Monitoring A/B test conversions...")
        try:
            # Check for winner and switch if needed
            stats = self.ab_engine.get_conversion_stats(hours=2)
            winner = self.ab_engine.determine_winner(stats)
            
            if winner:
                current = self.ab_engine.get_current_active_variant()
                if winner != current:
                    logger.info(f"üîÑ Auto-switching to winner: {winner}")
                    self.ab_engine.update_active_variant(winner)
                else:
                    logger.info(f"‚úÖ Winner unchanged: {winner} (conversion: {stats[winner]['conversion_rate']:.2%})")
            else:
                logger.info("‚è≥ Insufficient samples to determine winner")
        except Exception as e:
            logger.error(f"Error monitoring conversions: {e}")
    
    def scale_infrastructure(self):
        """Scale infrastructure based on demand"""
        logger.info("üöÄ Step 2: Scaling infrastructure...")
        try:
            self.scaler.auto_scale()
        except Exception as e:
            logger.error(f"Error scaling infrastructure: {e}")
    
    def clean_fake_data_task(self):
        """Clean all fake/mock data"""
        logger.info("üßπ Step 3: Cleaning fake data...")
        try:
            clean_fake_data()
        except Exception as e:
            logger.error(f"Error cleaning fake data: {e}")
    
    def prioritize_bugfixes(self):
        """Prioritize bug fixes from user feedback"""
        logger.info("üêõ Step 4: Prioritizing bug fixes...")
        try:
            # Auto-triage bugs
            self.bug_prioritizer.auto_triage()
            
            # Get priority bugs
            priority_bugs = self.bug_prioritizer.get_priority_bugs(limit=10)
            logger.info(f"üìã Found {len(priority_bugs)} priority bugs")
            
            for bug in priority_bugs:
                logger.info(f"  - {bug['title']} (Priority: {bug['priority_score']})")
        except Exception as e:
            logger.error(f"Error prioritizing bugs: {e}")
    
    def ensure_live_fomo(self):
        """Ensure all FOMO features show real-time live data"""
        logger.info("üî• Step 5: Ensuring live FOMO features...")
        try:
            # Check if leaderboard is updating in real-time
            # Check if airdrop counter is live
            # Check if celebration banners are showing
            logger.info("‚úÖ Live FOMO features verified")
        except Exception as e:
            logger.error(f"Error ensuring live FOMO: {e}")
    
    def migrate_enhancements(self):
        """Migrate pending enhancements to task queue"""
        logger.info("üìã Step 6: Migrating pending enhancements...")
        try:
            # Get pending count
            pending_count = self.enhancement_queue.get_pending_count()
            logger.info(f"üìä Pending enhancements: {pending_count}")
            
            # Get pending tasks
            pending_tasks = self.enhancement_queue.get_pending_tasks(limit=10)
            logger.info(f"üîç Top {len(pending_tasks)} pending tasks:")
            for task in pending_tasks:
                logger.info(f"  - {task['title']} (Priority: {task['priority']})")
        except Exception as e:
            logger.error(f"Error migrating enhancements: {e}")
    
    def run_full_protocol(self):
        """Run full post-audit protocol"""
        logger.info("=" * 60)
        logger.info("üöÄ POST-AUDIT PROTOCOL - STARTING")
        logger.info("=" * 60)
        
        start_time = datetime.utcnow()
        
        # Step 1: Monitor conversions/AB
        self.monitor_conversions_ab()
        
        # Step 2: Scale infrastructure
        self.scale_infrastructure()
        
        # Step 3: Clean fake data
        self.clean_fake_data_task()
        
        # Step 4: Prioritize bug fixes
        self.prioritize_bugfixes()
        
        # Step 5: Ensure live FOMO
        self.ensure_live_fomo()
        
        # Step 6: Migrate enhancements
        self.migrate_enhancements()
        
        end_time = datetime.utcnow()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("=" * 60)
        logger.info(f"‚úÖ POST-AUDIT PROTOCOL - COMPLETE ({duration:.2f}s)")
        logger.info("=" * 60)
        
        return {
            "status": "complete",
            "duration_seconds": duration,
            "timestamp": end_time.isoformat()
        }
    
    def run_continuous(self, interval_hours: int = 2):
        """Run protocol continuously every N hours"""
        logger.info(f"üîÑ Starting continuous post-audit protocol (every {interval_hours} hours)")
        
        while True:
            try:
                self.run_full_protocol()
                logger.info(f"‚è≥ Waiting {interval_hours} hours until next run...")
                time.sleep(interval_hours * 3600)
            except Exception as e:
                logger.error(f"Error in continuous protocol: {e}")
                time.sleep(300)  # Retry in 5 minutes on error

if __name__ == "__main__":
    protocol = PostAuditProtocol()
    
    # Run once
    protocol.run_full_protocol()
    
    # Or run continuously
    # protocol.run_continuous(interval_hours=2)

